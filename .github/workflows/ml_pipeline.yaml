name: ML Pipeline CI/CD

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main # Or specific branches like 'develop'

jobs:
  test_and_lint:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.11"]

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip' # Cache pip dependencies

    - name: Install dependencies
      run: |
        python -m venv venv
        source venv/bin/activate
        pip install --upgrade pip
        pip install -r requirements.txt
        # Ensure dev/test tools are installed if not in requirements.txt (they are for this project)

    - name: Run linters (Flake8 and Black --check)
      run: |
        source venv/bin/activate
        make lint

    - name: Run tests with coverage
      run: |
        source venv/bin/activate
        make test

    - name: Upload coverage report artifact
      uses: actions/upload-artifact@v4
      with:
        name: coverage-report-py${{ matrix.python-version }}
        path: htmlcov/
        if-no-files-found: warn # Use 'warn' or 'ignore' if report might not always exist

  train_model_on_main_merge:
    runs-on: ubuntu-latest
    needs: test_and_lint # Ensure tests and linting pass before training
    if: github.event_name == 'push' && github.ref == 'refs/heads/main' # Only run on merge to main

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m venv venv
        source venv/bin/activate
        pip install --upgrade pip
        pip install -r requirements.txt

    # Data is assumed to be in the repo for this assignment.
    # If data were external, a download step would be here.
    # e.g., using AWS CLI for S3, or DVC pull.

    - name: Run Training Pipeline
      id: training_run # Give an ID to this step to potentially use its outputs
      run: |
        source venv/bin/activate
        make train-pipeline # This uses the default src/config/config.yaml

    - name: Archive Model Artifacts
      uses: actions/upload-artifact@v4
      with:
        name: trained-model-artifacts
        path: | # Upload multiple paths
          artifacts/models/
          artifacts/metrics/latest_metrics.json
          artifacts/metrics/experiment_log.json
        if-no-files-found: error # Fail if critical artifacts are not found

    - name: Archive All Metrics
      uses: actions/upload-artifact@v4
      with:
        name: training-metrics
        path: artifacts/metrics/
        if-no-files-found: warn